<?xml version="1.0" encoding="UTF-8"?>

<!--druid的SQL日志输出-->
<!--ehcache缓存命中输出-->
<!--对方法通知输出-->
<!--Druid的监控记录在是缓存的，重启之后无法找回，所以需要做持久化，定期把监控记录转存到日志文件中-->
<!-- 从高到地低 OFF 、 FATAL 、 ERROR 、 WARN 、 INFO 、 DEBUG 、 TRACE 、 ALL -->
<!-- 日志输出规则  根据当前ROOT 级别，日志输出时，级别高于root默认的级别时  会输出 -->
<!-- 以下 每个配置的 filter 是过滤掉输出文件里面，会出现高级别文件，依然出现低级别的日志信息，通过filter 过滤只记录本级别的日志-->
<!--/代表项目在电脑磁盘的根目录  此时日志被输出到了E盘（我的项目在E盘）下的home文件夹中-->

<configuration scan="true" scanPeriod="60 seconds" debug="false">

    <!-- 定义日志文件 输入位置 -->
    <property name="LOG_HOME" value="logback"/>

    <!-- 对日志进行格式化 -->
    <property name="file_pattern" value="%date{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level%logger{56}.%method:%L -%msg%n"/>
    <property name="console_pattern" value="%boldBlue(%d{yyyy-MM-dd}) %highlight(%d{HH:mm:ss:SSS})  %boldBlue(%thread) %highlight(%-5level) %boldMagenta(%logger{36}) - %cyan(%msg%n)"/>

    <!-- 日志最大的历史 7天 -->
    <property name="maxHistory" value="3"/>

    <!--日志最大的容量-->
    <property name="maxFileSize" value="10MB"/>

    <!-- ConsoleAppender 控制台输出日志 -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>${console_pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>


    <!-- All级别日志 -->
    <appender name="ALL"  class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!--日志文件名-->
        <file>${LOG_HOME}/all-level.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!--日志文件名-->
            <fileNamePattern>${LOG_HOME}/all-level.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <!-- 除按日志记录之外，还配置了日志文件不能超过10M(默认)，若超过10M，日志文件会以索引0开始， -->
            <!--日志最大的容量-->
            <maxFileSize>${maxFileSize}</maxFileSize>
            <!-- 日志最大的历史-->
            <maxHistory>${maxHistory}</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>${file_pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!-- ERROR级别日志 -->
    <appender name="ERROR" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!--日志文件名-->
        <file>${LOG_HOME}/error-level.log</file>
        <!-- 设置滚动策略 TimeBasedRollingPolicy 按日期滚动 -->
        <!--滚动输出支持自动压缩,文件名以.gz或者.zip结尾即可，例如：/wombat/foo.%d.gz-->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${LOG_HOME}/error-level.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <!-- 除按日志记录之外，还配置了日志文件不能超过10M(默认)，若超过10M，日志文件会以索引0开始， -->
            <!--日志最大的容量-->
            <maxFileSize>${maxFileSize}</maxFileSize>
            <!-- 日志最大的历史-->
            <maxHistory>${maxHistory}</maxHistory>
        </rollingPolicy>
        <!-- 对日志格式编码 -->
        <encoder>
            <pattern>${file_pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 过滤器，只记录WARN级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <!--过滤级别-->
            <level>ERROR</level>
            <!--用于配置符合过滤条件的操作-->
            <onMatch>ACCEPT</onMatch>
            <!--用于配置不符合过滤条件的操作-->
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <!-- WARN级别日志 appender -->
    <appender name="WARN" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_HOME}/warn-level.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${LOG_HOME}/warn-level.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <!-- 除按日志记录之外，还配置了日志文件不能超过10M(默认)，若超过10M，日志文件会以索引0开始， -->
            <!--日志最大的容量-->
            <maxFileSize>${maxFileSize}</maxFileSize>
            <!-- 日志最大的历史-->
            <maxHistory>${maxHistory}</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>${file_pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 过滤器，只记录WARN级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>WARN</level>
            <!--用于配置符合过滤条件的操作-->
            <onMatch>ACCEPT</onMatch>
            <!--用于配置不符合过滤条件的操作-->
            <onMismatch>DENY</onMismatch>
        </filter>

    </appender>

    <!-- INFO级别日志  -->
    <appender name="INFO" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 过滤器，只记录INFO级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <file>${LOG_HOME}/info-level.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- 按天回滚 daily -->
            <fileNamePattern>${LOG_HOME}/info-level.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <!-- 除按日志记录之外，还配置了日志文件不能超过10M(默认)，若超过10M，日志文件会以索引0开始， -->
            <!--日志最大的容量-->
            <maxFileSize>${maxFileSize}</maxFileSize>
            <!-- 日志最大的历史-->
            <maxHistory>${maxHistory}</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>${file_pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!-- DEBUG级别日志 -->
    <appender name="DEBUG" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 过滤器，只记录DEBUG级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>DEBUG</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <file>${LOG_HOME}/debug-level.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- 按天回滚 daily -->
            <fileNamePattern>${LOG_HOME}/debug-level.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <!-- 除按日志记录之外，还配置了日志文件不能超过10M(默认)，若超过10M，日志文件会以索引0开始， -->
            <!--日志最大的容量-->
            <maxFileSize>${maxFileSize}</maxFileSize>
            <!-- 日志最大的历史-->
            <maxHistory>${maxHistory}</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>${file_pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!-- TRACE级别日志 -->
    <appender name="TRACE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 过滤器，只记录ERROR级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>TRACE</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <file>${LOG_HOME}/trace-level.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- 按天回滚 daily -->
            <fileNamePattern>${LOG_HOME}/trace-level.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <!-- 除按日志记录之外，还配置了日志文件不能超过10M(默认)，若超过10M，日志文件会以索引0开始， -->
            <!--日志最大的容量-->
            <maxFileSize>${maxFileSize}</maxFileSize>
            <!-- 日志最大的历史-->
            <maxHistory>${maxHistory}</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>${file_pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!--druidMonitor级日志-->
    <appender name="druidMonitorRollingFile" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_HOME}/druid-monitor.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${LOG_HOME}/druid-monitor.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <!-- 除按日志记录之外，还配置了日志文件不能超过10M(默认)，若超过10M，日志文件会以索引0开始， -->
            <!--日志最大的容量-->
            <maxFileSize>${maxFileSize}</maxFileSize>
            <!-- 日志最大的历史-->
            <maxHistory>${maxHistory}</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>${file_pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!--druidSql级日志-->
    <appender name="druidSqlRollingFile" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_HOME}/druid-Sql.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${LOG_HOME}/druid-Sql.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <!-- 日志最大的历史 60天 -->
            <!-- 除按日志记录之外，还配置了日志文件不能超过10M(默认)，若超过10M，日志文件会以索引0开始， -->
            <!--日志最大的容量-->
            <maxFileSize>${maxFileSize}</maxFileSize>
            <!-- 日志最大的历史-->
            <maxHistory>${maxHistory}</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>${file_pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>

    </appender>

    <!--controller级日志-->
    <appender name="FILE_CONTROLLER_LOG" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <file>${LOG_HOME}/controller.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${LOG_HOME}/controller.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <!-- 日志最大的历史 60天 -->
            <!-- 除按日志记录之外，还配置了日志文件不能超过10M(默认)，若超过10M，日志文件会以索引0开始， -->
            <!--日志最大的容量-->
            <maxFileSize>${maxFileSize}</maxFileSize>
            <!-- 日志最大的历史-->
            <maxHistory>${maxHistory}</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>${file_pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!--controller异步输出 -->
    <appender name ="ASYNC_CONTROLLER_LOG" class= "ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref ="FILE_CONTROLLER_LOG"/>
    </appender>

    <!-- 异步TRACE输出 -->
    <appender name ="ASYNC_TRACE" class= "ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!--不阻塞线程但日志有可能丢失-->
        <neverBlock>true</neverBlock>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref ="TRACE"/>
    </appender>

    <!-- 异步DEBUG输出 -->
    <appender name ="ASYNC_DEBUG" class= "ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!--不阻塞线程但日志有可能丢失-->
        <neverBlock>true</neverBlock>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref ="DEBUG"/>
    </appender>

    <!-- 异步INFO输出 -->
    <appender name ="ASYNC_INFO" class= "ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!--不阻塞线程但日志有可能丢失-->
        <neverBlock>true</neverBlock>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref ="INFO"/>
    </appender>

    <!-- 异步WARN输出 -->
    <appender name ="ASYNC_WARN" class= "ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!--不阻塞线程但日志有可能丢失-->
        <neverBlock>true</neverBlock>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref ="WARN"/>
    </appender>

    <!-- 异步ERROR输出 -->
    <appender name ="ASYNC_ERROR" class= "ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!--不阻塞线程但日志有可能丢失-->
        <neverBlock>true</neverBlock>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref ="ERROR"/>
    </appender>

    <!-- 异步ALL输出 -->
    <appender name ="ASYNC_ALL" class= "ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!--不阻塞线程但日志有可能丢失-->
        <neverBlock>true</neverBlock>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref ="ALL"/>
    </appender>

    <!-- 异步druidMonitorRollingFile输出 -->
    <appender name ="ASYNC_druidMonitor" class= "ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!--不阻塞线程但日志有可能丢失-->
        <neverBlock>true</neverBlock>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref ="druidMonitorRollingFile"/>
    </appender>

    <!-- 异步druidSql输出 -->
    <appender name ="ASYNC_druidSql" class= "ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!--不阻塞线程但日志有可能丢失-->
        <neverBlock>true</neverBlock>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref ="druidSqlRollingFile"/>
    </appender>

    <!--自定义logback的扩展appender-->
    <!--    <appender name="FILE_SELF" class="com.company.project.core.log.MyAppender">

            <encoder>
                <pattern>%d{yyyy/MM/dd HH:mm:ss.SSS} %-5level [%thread] [%c{0}:%L] : %msg%n</pattern>
                <charset>UTF-8</charset>
            </encoder>
            <filter class="ch.qos.logback.classic.filter.LevelFilter">
                <level>ERROR</level>
                <onMatch>ACCEPT</onMatch>
                <onMismatch>DENY</onMismatch>
            </filter>
        </appender>-->

    <!-- root级别DEBUG -->
    <root level="debug">
        <!-- 控制台输出 -->
        <appender-ref ref="STDOUT"/>
        <!-- 文件输出 -->
        <appender-ref ref="ASYNC_TRACE"/>
        <appender-ref ref="ASYNC_DEBUG"/>
        <appender-ref ref="ASYNC_INFO" />
        <appender-ref ref="ASYNC_WARN"/>
        <appender-ref ref="ASYNC_ERROR"/>
        <appender-ref ref="ASYNC_ALL" />
        <appender-ref ref="ASYNC_druidMonitor"/>
    </root>

    <!-- 很多人使用Mybatis的时候，控制台不能输出SQL语句，造成调试困难。只需要让DAO层的日志级别调整为DEBUG就可以了 -->
     <logger name="com.aldrich.mapper" level="DEBUG" />

    <!--配置druid的SQL日志输出-->
    <logger name="druid.sql.Statement" level="DEBUG" additivity="false">
        <appender-ref ref="ASYNC_druidSql" />
    </logger>

    <!--配置druid的监控日志输出-->
    <logger name="com.company.project.support.druid.MyDruidDataSourceStatLoggerAdapter" level="DEBUG" additivity="false">
        <appender-ref ref="ASYNC_druidMonitor" />
    </logger>


    <!--配置定时任务DruidLogTask的监控日志输出-->
    <logger name="com.company.project.timetask.DruidLogTask" level="DEBUG" additivity="false">
        <appender-ref ref="ASYNC_druidMonitor" />
    </logger>


    <!--配置aop对controller参数日志的监控-->
    <logger name="com.company.project.support.aop.ControllerLogAop" level="INFO" additivity="false">
        <appender-ref ref="ASYNC_CONTROLLER_LOG" />
    </logger>

    <!--myibatis log configure-->
    <logger name="com.apache.ibatis" level="TRACE"/>
    <logger name="java.sql.Connection" level="DEBUG"/>
    <logger name="java.sql.Statement" level="DEBUG"/>
    <logger name="java.sql.PreparedStatement" level="DEBUG"/>


    <logger name="org.springframework.scheduling" level="INFO"/>
    <logger name="org.springframework.session" level="INFO"/>

    <logger name="org.apache.catalina.startup.DigesterFactory" level="ERROR"/>
    <logger name="org.apache.catalina.util.LifecycleBase" level="ERROR"/>
    <logger name="org.apache.coyote.http11.Http11NioProtocol" level="WARN"/>
    <logger name="org.apache.sshd.common.util.SecurityUtils" level="WARN"/>
    <logger name="org.apache.tomcat.util.net.NioSelectorPool" level="WARN"/>
    <logger name="org.crsh.plugin" level="WARN"/>
    <logger name="org.crsh.ssh" level="WARN"/>
    <logger name="org.eclipse.jetty.util.component.AbstractLifeCycle" level="ERROR"/>
    <logger name="org.hibernate.validator.internal.util.Version" level="WARN"/>
    <logger name="org.springframework.boot.actuate.autoconfigure.CrshAutoConfiguration" level="WARN"/>

</configuration>
